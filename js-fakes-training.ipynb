{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRaw = loadMidiInFolder(pathes['data_dir'], 'data/trainDataRaw')\n",
    "testDataRaw = loadMidiInFolder(pathes['test_dir'], 'data/testDataRaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = concatMidi(trainDataRaw)\n",
    "testData = concatMidi(testDataRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for each track or collect all (now).\n",
    "\n",
    "beat2idx = []\n",
    "idx2beat = []\n",
    "params['vocab_size'] = []\n",
    "\n",
    "vocabularies = set()\n",
    "\n",
    "for track in range(len(trainData)):\n",
    "    vocabularies = vocabularies | set(trainData[track]) | set(testData[track])\n",
    "for track in range(len(trainData)):\n",
    "    params['vocab_size'].append(len(vocabularies))\n",
    "    beat2idx.append({beat: i for i, beat in enumerate(vocabularies)})\n",
    "    idx2beat.append({idx:beat for beat, idx in beat2idx[track].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1499, 1499, 1499, 1499]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in range(len(trainData)):\n",
    "\n",
    "    trainData[track] = np.array([beat2idx[track][beat] for beat in trainData[track]])\n",
    "    testData[track] = np.array([beat2idx[track][beat] for beat in testData[track]])\n",
    "\n",
    "trainData = trainData.astype(int)\n",
    "testData = testData.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasets = []\n",
    "testDatasets = []\n",
    "for track in range(len(trainData)):\n",
    "    trainDatasets.append(makeDataset(trainData[track], track))\n",
    "    testDatasets.append(makeDataset(testData[track], track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((16, 16), (16, 16, 1499)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "name = 'single-track-lstm-training'\n",
    "track = 0\n",
    "model = makeSingleTrackModel(track)\n",
    "fig = plot_model(model, to_file=name+'.png', show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if config['output']['wandb']:\n",
    "    wandb.init(config=params, project='lstm-singletrack-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(trainDatasets[track], validation_data=testDatasets[track], batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for track in range(params['track_size']):\n",
    "\n",
    "    x = list(trainDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    y = list(trainDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    val_x = list(testDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    val_y = list(testDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "    x_val.append(val_x)\n",
    "    y_val.append(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 16, 1499), (16, 16), (16, 16, 1499))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape, y_train[0].shape, x_val[0].shape, y_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer input1-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input1-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input2-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input2-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input3-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input3-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input4-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input4-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "name = 'multi-track-lstm-training-5'\n",
    "model = makeMultiTrackModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.init(config=params, project='lstm-multi-track-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Single Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = np.array([trainData[0, initBeatIndex:initBeatIndex+params['sequence_length']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initBeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 70.71it/s]\n"
     ]
    }
   ],
   "source": [
    "weight = 'model-single-track-lstm-training-05-4.0770.hdf5'\n",
    "\n",
    "model = makeSingleTrackModel(track, 1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = pred.numpy().squeeze()\n",
    "\n",
    "music_sequence = []\n",
    "\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    topk = tf.math.top_k(pred[-1], 3)\n",
    "    topkChoices = topk[1].numpy().squeeze()\n",
    "    topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "    # Apply random\n",
    "    next_beat = None\n",
    "    if np.random.uniform(0, 1) < .5:\n",
    "        next_beat = topkChoices[0]\n",
    "    else:\n",
    "        p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "        next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "    music_sequence.append(idx2beat[track][next_beat])\n",
    "\n",
    "    pred = model(np.array([[next_beat]]))\n",
    "    pred = tf.expand_dims(pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi(name+'.mid', [music_sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Multi Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = []\n",
    "for track in range(params['track_size']):\n",
    "    initBeat.append(np.array([trainData[track, initBeatIndex:initBeatIndex+params['sequence_length']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 'model-multi-track-lstm-training-4-998-1.0914.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeMultiTrackModel(1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = [p.numpy().squeeze() for p in pred]\n",
    "\n",
    "music_sequence = []\n",
    "for track in range(params['track_size']):\n",
    "    music_sequence.append([idx2beat[track][idx] for idx in initBeat[track][0].tolist()])\n",
    "\n",
    "outputs['length'] = 100\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    nextBeatList = []\n",
    "    for index, p in enumerate(pred):\n",
    "        topk = tf.math.top_k(p[-1], 3)\n",
    "        topkChoices = topk[1].numpy().squeeze()\n",
    "        topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "        # Apply random\n",
    "        # next_beat = topkChoices[0]\n",
    "        next_beat = None\n",
    "        if np.random.uniform(0, 1) < .5:\n",
    "            next_beat = topkChoices[0]\n",
    "        else:\n",
    "            p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "            next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "        music_sequence[index].append(idx2beat[index][next_beat])\n",
    "        nextBeatList.append(np.array([[next_beat]]))\n",
    "\n",
    "    pred = model.predict(nextBeatList, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi('new100-4-2'+'.mid', music_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model(model, to_file=name+'.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('lofi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af42d6b00596c858df57cfb1e3d56019ad36764fdda4c39cb12fa72d6aaee7c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
