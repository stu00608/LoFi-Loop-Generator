{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRaw = loadMidiInFolder(pathes['data_dir'], 'data/trainDataRaw')\n",
    "testDataRaw = loadMidiInFolder(pathes['test_dir'], 'data/testDataRaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = concatMidi(trainDataRaw)\n",
    "testData = concatMidi(testDataRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for each track or collect all (now).\n",
    "\n",
    "beat2idx = []\n",
    "idx2beat = []\n",
    "params['vocab_size'] = []\n",
    "\n",
    "vocabularies = set()\n",
    "\n",
    "# Make dictionary across 4 tracks.\n",
    "# for track in range(len(trainData)):\n",
    "#     vocabularies = vocabularies | set(trainData[track]) | set(testData[track])\n",
    "# for track in range(len(trainData)):\n",
    "#     params['vocmakeSingleTrackModelab_size'].append(len(vocabularies))\n",
    "#     beat2idx.append({beat: i for i, beat in enumerate(vocabularies)})\n",
    "#     idx2beat.append({idx:beat for beat, idx in beat2idx[track].items()})\n",
    "\n",
    "# Make dictionary for each track\n",
    "for track in range(len(trainData)):\n",
    "    vocabularies = set(trainData[track]) | set(testData[track])\n",
    "    params['vocab_size'].append(len(vocabularies))\n",
    "    beat2idx.append({beat: i for i, beat in enumerate(vocabularies)})\n",
    "    idx2beat.append({idx:beat for beat, idx in beat2idx[track].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[296, 635, 813, 545]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in range(len(trainData)):\n",
    "\n",
    "    trainData[track] = np.array([beat2idx[track][beat] for beat in trainData[track]])\n",
    "    testData[track] = np.array([beat2idx[track][beat] for beat in testData[track]])\n",
    "\n",
    "trainData = trainData.astype(int)\n",
    "testData = testData.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasets = []\n",
    "testDatasets = []\n",
    "for track in range(len(trainData)):\n",
    "    trainDatasets.append(makeDataset(trainData[track], track))\n",
    "    testDatasets.append(makeDataset(testData[track], track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 16), (64, 16, 296)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "name = 'single-track-lstm-training-wandb-exp-5'\n",
    "track = 0\n",
    "model = makeSingleTrackModel(track)\n",
    "fig = plot_model(model, to_file=name+'.png', show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstu00608\u001b[0m (\u001b[33mtku-cilab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/stu00608/Repositories/lofi-loop-generator/wandb/run-20220627_180421-20g5tg1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tku-cilab/lstm-singletrack-js-fake/runs/20g5tg1s\" target=\"_blank\">likely-feather-105</a></strong> to <a href=\"https://wandb.ai/tku-cilab/lstm-singletrack-js-fake\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 4s 69ms/step - loss: 5.6482 - acc: 0.0382 - val_loss: 5.6689 - val_acc: 0.1335\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 5.3082 - acc: 0.1189 - val_loss: 5.6235 - val_acc: 0.1341\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 4.7934 - acc: 0.1286 - val_loss: 5.6103 - val_acc: 0.1364\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 4.4993 - acc: 0.1379 - val_loss: 5.5787 - val_acc: 0.1403\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 4.2331 - acc: 0.1410 - val_loss: 5.5285 - val_acc: 0.1453\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 4.0527 - acc: 0.1494 - val_loss: 5.4731 - val_acc: 0.1470\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 3.9232 - acc: 0.1463 - val_loss: 5.4120 - val_acc: 0.1483\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 3.7749 - acc: 0.1635 - val_loss: 5.3491 - val_acc: 0.1533\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.6551 - acc: 0.1682 - val_loss: 5.2729 - val_acc: 0.1561\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.5805 - acc: 0.1662 - val_loss: 5.1937 - val_acc: 0.1574\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.4755 - acc: 0.1704 - val_loss: 5.1158 - val_acc: 0.1540\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.3711 - acc: 0.1762 - val_loss: 5.0193 - val_acc: 0.1642\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.3551 - acc: 0.1795 - val_loss: 4.9157 - val_acc: 0.1662\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 3.2362 - acc: 0.1843 - val_loss: 4.8204 - val_acc: 0.1652\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 3.1741 - acc: 0.1905 - val_loss: 4.7026 - val_acc: 0.1774\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.1718 - acc: 0.1912 - val_loss: 4.5847 - val_acc: 0.1844\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.0943 - acc: 0.1936 - val_loss: 4.4494 - val_acc: 0.1919\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.0876 - acc: 0.1968 - val_loss: 4.3205 - val_acc: 0.1925\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.0477 - acc: 0.2005 - val_loss: 4.1917 - val_acc: 0.2046\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 3.0058 - acc: 0.2096 - val_loss: 4.0421 - val_acc: 0.2059\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.9740 - acc: 0.2045 - val_loss: 3.9038 - val_acc: 0.2108\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.9499 - acc: 0.2160 - val_loss: 3.7691 - val_acc: 0.2194\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.9210 - acc: 0.2231 - val_loss: 3.6546 - val_acc: 0.2134\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 2.9070 - acc: 0.2186 - val_loss: 3.5031 - val_acc: 0.2231\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.8711 - acc: 0.2288 - val_loss: 3.3792 - val_acc: 0.2264\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.8492 - acc: 0.2338 - val_loss: 3.2765 - val_acc: 0.2329\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.8160 - acc: 0.2308 - val_loss: 3.1622 - val_acc: 0.2327\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.8513 - acc: 0.2366 - val_loss: 3.0820 - val_acc: 0.2373\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.7668 - acc: 0.2473 - val_loss: 3.0159 - val_acc: 0.2402\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.7767 - acc: 0.2419 - val_loss: 2.9295 - val_acc: 0.2467\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 2.7380 - acc: 0.2478 - val_loss: 2.8767 - val_acc: 0.2508\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 2.7449 - acc: 0.2438 - val_loss: 2.8482 - val_acc: 0.2510\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.6912 - acc: 0.2528 - val_loss: 2.8218 - val_acc: 0.2458\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.7382 - acc: 0.2496 - val_loss: 2.7877 - val_acc: 0.2619\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.6783 - acc: 0.2592 - val_loss: 2.7660 - val_acc: 0.2635\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 2.7072 - acc: 0.2611 - val_loss: 2.7492 - val_acc: 0.2601\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 2.6855 - acc: 0.2584 - val_loss: 2.7214 - val_acc: 0.2689\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 2.6552 - acc: 0.2670 - val_loss: 2.7039 - val_acc: 0.2767\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 2.6334 - acc: 0.2660 - val_loss: 2.7203 - val_acc: 0.2690\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 2.6098 - acc: 0.2719 - val_loss: 2.6990 - val_acc: 0.2739\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 2.5955 - acc: 0.2785 - val_loss: 2.6863 - val_acc: 0.2798\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.5809 - acc: 0.2733 - val_loss: 2.6652 - val_acc: 0.2746\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.5573 - acc: 0.2848 - val_loss: 2.6583 - val_acc: 0.2757\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.5694 - acc: 0.2793 - val_loss: 2.6576 - val_acc: 0.2770\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 2.5501 - acc: 0.2831 - val_loss: 2.6417 - val_acc: 0.2817\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.5353 - acc: 0.2826 - val_loss: 2.6587 - val_acc: 0.2803\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.5424 - acc: 0.2809 - val_loss: 2.6416 - val_acc: 0.2728\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.5182 - acc: 0.2869 - val_loss: 2.6286 - val_acc: 0.2811\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.5111 - acc: 0.2861 - val_loss: 2.6032 - val_acc: 0.2834\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.4938 - acc: 0.2917 - val_loss: 2.6161 - val_acc: 0.2873\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.4845 - acc: 0.2927 - val_loss: 2.6251 - val_acc: 0.2790\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.4939 - acc: 0.2895 - val_loss: 2.6153 - val_acc: 0.2882\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.4677 - acc: 0.2963 - val_loss: 2.6165 - val_acc: 0.2769\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.4719 - acc: 0.2970 - val_loss: 2.5912 - val_acc: 0.2821\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.4384 - acc: 0.3050 - val_loss: 2.5863 - val_acc: 0.2819\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.4474 - acc: 0.3032 - val_loss: 2.5866 - val_acc: 0.2826\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.4444 - acc: 0.2994 - val_loss: 2.5842 - val_acc: 0.2830\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.4225 - acc: 0.2995 - val_loss: 2.6010 - val_acc: 0.2829\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.4135 - acc: 0.3050 - val_loss: 2.5755 - val_acc: 0.2871\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3920 - acc: 0.3136 - val_loss: 2.5861 - val_acc: 0.2799\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.4076 - acc: 0.3047 - val_loss: 2.5756 - val_acc: 0.2873\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 38ms/step - loss: 2.3764 - acc: 0.3061 - val_loss: 2.5696 - val_acc: 0.2860\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3786 - acc: 0.3117 - val_loss: 2.5679 - val_acc: 0.2803\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3650 - acc: 0.3139 - val_loss: 2.5814 - val_acc: 0.2808\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3655 - acc: 0.3123 - val_loss: 2.5629 - val_acc: 0.2829\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3397 - acc: 0.3216 - val_loss: 2.5561 - val_acc: 0.2886\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3343 - acc: 0.3216 - val_loss: 2.5564 - val_acc: 0.2799\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 2.3341 - acc: 0.3160 - val_loss: 2.5538 - val_acc: 0.2907\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3236 - acc: 0.3216 - val_loss: 2.5428 - val_acc: 0.2839\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3329 - acc: 0.3190 - val_loss: 2.5703 - val_acc: 0.2765\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2994 - acc: 0.3230 - val_loss: 2.5430 - val_acc: 0.2830\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3083 - acc: 0.3123 - val_loss: 2.5539 - val_acc: 0.2835\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2931 - acc: 0.3279 - val_loss: 2.5334 - val_acc: 0.2832\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2852 - acc: 0.3332 - val_loss: 2.5439 - val_acc: 0.2822\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.3005 - acc: 0.3184 - val_loss: 2.5449 - val_acc: 0.2858\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2758 - acc: 0.3311 - val_loss: 2.5385 - val_acc: 0.2865\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.2569 - acc: 0.3303 - val_loss: 2.5112 - val_acc: 0.2865\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2452 - acc: 0.3377 - val_loss: 2.5500 - val_acc: 0.2783\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2520 - acc: 0.3342 - val_loss: 2.5416 - val_acc: 0.2799\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2501 - acc: 0.3357 - val_loss: 2.5452 - val_acc: 0.2842\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2404 - acc: 0.3351 - val_loss: 2.5364 - val_acc: 0.2845\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2283 - acc: 0.3320 - val_loss: 2.5277 - val_acc: 0.2850\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2200 - acc: 0.3382 - val_loss: 2.5406 - val_acc: 0.2852\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.2034 - acc: 0.3419 - val_loss: 2.5231 - val_acc: 0.2863\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1876 - acc: 0.3427 - val_loss: 2.5049 - val_acc: 0.2897\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.2073 - acc: 0.3348 - val_loss: 2.5309 - val_acc: 0.2845\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1718 - acc: 0.3515 - val_loss: 2.5275 - val_acc: 0.2842\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1792 - acc: 0.3423 - val_loss: 2.5331 - val_acc: 0.2865\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1685 - acc: 0.3403 - val_loss: 2.5422 - val_acc: 0.2806\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1515 - acc: 0.3527 - val_loss: 2.5346 - val_acc: 0.2829\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1705 - acc: 0.3494 - val_loss: 2.5401 - val_acc: 0.2746\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1343 - acc: 0.3506 - val_loss: 2.5462 - val_acc: 0.2773\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1367 - acc: 0.3556 - val_loss: 2.5388 - val_acc: 0.2850\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1239 - acc: 0.3535 - val_loss: 2.5373 - val_acc: 0.2842\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1296 - acc: 0.3501 - val_loss: 2.5525 - val_acc: 0.2821\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1270 - acc: 0.3513 - val_loss: 2.5176 - val_acc: 0.2821\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1183 - acc: 0.3600 - val_loss: 2.5359 - val_acc: 0.2806\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1284 - acc: 0.3598 - val_loss: 2.5320 - val_acc: 0.2829\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.1066 - acc: 0.3649 - val_loss: 2.5253 - val_acc: 0.2809\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 2.0948 - acc: 0.3653 - val_loss: 2.5376 - val_acc: 0.2830\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 2.0982 - acc: 0.3615 - val_loss: 2.5418 - val_acc: 0.2814\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0794 - acc: 0.3662 - val_loss: 2.5615 - val_acc: 0.2767\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0696 - acc: 0.3629 - val_loss: 2.5281 - val_acc: 0.2853\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0705 - acc: 0.3658 - val_loss: 2.5517 - val_acc: 0.2791\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0710 - acc: 0.3639 - val_loss: 2.5363 - val_acc: 0.2850\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0636 - acc: 0.3645 - val_loss: 2.5526 - val_acc: 0.2826\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0705 - acc: 0.3694 - val_loss: 2.5516 - val_acc: 0.2860\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0374 - acc: 0.3758 - val_loss: 2.5726 - val_acc: 0.2772\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0238 - acc: 0.3746 - val_loss: 2.5588 - val_acc: 0.2786\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0283 - acc: 0.3798 - val_loss: 2.5642 - val_acc: 0.2793\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0242 - acc: 0.3796 - val_loss: 2.5511 - val_acc: 0.2801\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0352 - acc: 0.3768 - val_loss: 2.5563 - val_acc: 0.2759\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9954 - acc: 0.3852 - val_loss: 2.5734 - val_acc: 0.2778\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 2.0172 - acc: 0.3816 - val_loss: 2.5873 - val_acc: 0.2796\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9982 - acc: 0.3831 - val_loss: 2.5596 - val_acc: 0.2817\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 1.9882 - acc: 0.3865 - val_loss: 2.5608 - val_acc: 0.2788\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9819 - acc: 0.3854 - val_loss: 2.5877 - val_acc: 0.2786\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9539 - acc: 0.3887 - val_loss: 2.5894 - val_acc: 0.2819\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9622 - acc: 0.3939 - val_loss: 2.5811 - val_acc: 0.2801\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9796 - acc: 0.3898 - val_loss: 2.6043 - val_acc: 0.2733\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.9488 - acc: 0.3969 - val_loss: 2.5574 - val_acc: 0.2843\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9560 - acc: 0.3938 - val_loss: 2.5844 - val_acc: 0.2790\n",
      "Epoch 123/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9388 - acc: 0.3953 - val_loss: 2.5999 - val_acc: 0.2817\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9476 - acc: 0.3957 - val_loss: 2.5943 - val_acc: 0.2764\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9315 - acc: 0.3993 - val_loss: 2.6033 - val_acc: 0.2770\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9038 - acc: 0.4067 - val_loss: 2.5987 - val_acc: 0.2729\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.9103 - acc: 0.4106 - val_loss: 2.5926 - val_acc: 0.2743\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9040 - acc: 0.4036 - val_loss: 2.6075 - val_acc: 0.2762\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8912 - acc: 0.4061 - val_loss: 2.6233 - val_acc: 0.2786\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.9001 - acc: 0.4035 - val_loss: 2.6021 - val_acc: 0.2778\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8739 - acc: 0.4146 - val_loss: 2.6235 - val_acc: 0.2801\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8726 - acc: 0.4183 - val_loss: 2.6060 - val_acc: 0.2778\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8810 - acc: 0.4122 - val_loss: 2.6135 - val_acc: 0.2749\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8739 - acc: 0.4153 - val_loss: 2.6419 - val_acc: 0.2733\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8686 - acc: 0.4195 - val_loss: 2.6193 - val_acc: 0.2759\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8420 - acc: 0.4213 - val_loss: 2.6123 - val_acc: 0.2769\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8421 - acc: 0.4247 - val_loss: 2.6330 - val_acc: 0.2716\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8374 - acc: 0.4240 - val_loss: 2.6416 - val_acc: 0.2757\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8383 - acc: 0.4313 - val_loss: 2.6502 - val_acc: 0.2741\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.8161 - acc: 0.4304 - val_loss: 2.6236 - val_acc: 0.2729\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8131 - acc: 0.4330 - val_loss: 2.6434 - val_acc: 0.2736\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8038 - acc: 0.4340 - val_loss: 2.6616 - val_acc: 0.2749\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.8034 - acc: 0.4336 - val_loss: 2.6500 - val_acc: 0.2773\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7822 - acc: 0.4402 - val_loss: 2.6603 - val_acc: 0.2743\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7961 - acc: 0.4341 - val_loss: 2.6664 - val_acc: 0.2689\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7868 - acc: 0.4363 - val_loss: 2.6713 - val_acc: 0.2739\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7793 - acc: 0.4412 - val_loss: 2.6626 - val_acc: 0.2703\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7644 - acc: 0.4443 - val_loss: 2.6907 - val_acc: 0.2731\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7749 - acc: 0.4403 - val_loss: 2.6933 - val_acc: 0.2694\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.7429 - acc: 0.4481 - val_loss: 2.6705 - val_acc: 0.2765\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7655 - acc: 0.4338 - val_loss: 2.6728 - val_acc: 0.2725\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7216 - acc: 0.4509 - val_loss: 2.6874 - val_acc: 0.2731\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7470 - acc: 0.4496 - val_loss: 2.6894 - val_acc: 0.2718\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.7340 - acc: 0.4464 - val_loss: 2.6898 - val_acc: 0.2713\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.7293 - acc: 0.4543 - val_loss: 2.6937 - val_acc: 0.2754\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7189 - acc: 0.4498 - val_loss: 2.6981 - val_acc: 0.2764\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.7251 - acc: 0.4600 - val_loss: 2.7096 - val_acc: 0.2731\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.7141 - acc: 0.4586 - val_loss: 2.7426 - val_acc: 0.2651\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6916 - acc: 0.4697 - val_loss: 2.7381 - val_acc: 0.2697\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6838 - acc: 0.4612 - val_loss: 2.7398 - val_acc: 0.2668\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6949 - acc: 0.4600 - val_loss: 2.7311 - val_acc: 0.2690\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6708 - acc: 0.4685 - val_loss: 2.7038 - val_acc: 0.2752\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6781 - acc: 0.4665 - val_loss: 2.7271 - val_acc: 0.2689\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 1.6440 - acc: 0.4781 - val_loss: 2.7244 - val_acc: 0.2705\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6513 - acc: 0.4761 - val_loss: 2.7163 - val_acc: 0.2756\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6588 - acc: 0.4746 - val_loss: 2.7471 - val_acc: 0.2677\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.6571 - acc: 0.4738 - val_loss: 2.7577 - val_acc: 0.2681\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6392 - acc: 0.4785 - val_loss: 2.7518 - val_acc: 0.2684\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6241 - acc: 0.4863 - val_loss: 2.7713 - val_acc: 0.2682\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6237 - acc: 0.4826 - val_loss: 2.7413 - val_acc: 0.2718\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6072 - acc: 0.4906 - val_loss: 2.7760 - val_acc: 0.2676\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6087 - acc: 0.4843 - val_loss: 2.7276 - val_acc: 0.2684\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.6114 - acc: 0.4875 - val_loss: 2.7525 - val_acc: 0.2715\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5895 - acc: 0.4931 - val_loss: 2.7478 - val_acc: 0.2733\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.5891 - acc: 0.4968 - val_loss: 2.7790 - val_acc: 0.2677\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5741 - acc: 0.4993 - val_loss: 2.7832 - val_acc: 0.2663\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5806 - acc: 0.4949 - val_loss: 2.7845 - val_acc: 0.2677\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5641 - acc: 0.5044 - val_loss: 2.7889 - val_acc: 0.2738\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5553 - acc: 0.5083 - val_loss: 2.7891 - val_acc: 0.2703\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5688 - acc: 0.5023 - val_loss: 2.7844 - val_acc: 0.2655\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.5472 - acc: 0.5073 - val_loss: 2.8253 - val_acc: 0.2677\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5302 - acc: 0.5134 - val_loss: 2.8192 - val_acc: 0.2655\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5312 - acc: 0.5076 - val_loss: 2.8067 - val_acc: 0.2677\n",
      "Epoch 184/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5379 - acc: 0.5093 - val_loss: 2.8079 - val_acc: 0.2708\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5485 - acc: 0.5036 - val_loss: 2.8222 - val_acc: 0.2682\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5315 - acc: 0.5050 - val_loss: 2.8221 - val_acc: 0.2630\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5156 - acc: 0.5216 - val_loss: 2.8114 - val_acc: 0.2669\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5070 - acc: 0.5214 - val_loss: 2.8498 - val_acc: 0.2656\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.5029 - acc: 0.5199 - val_loss: 2.8232 - val_acc: 0.2658\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4870 - acc: 0.5241 - val_loss: 2.8395 - val_acc: 0.2671\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4936 - acc: 0.5203 - val_loss: 2.8431 - val_acc: 0.2712\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4737 - acc: 0.5309 - val_loss: 2.8067 - val_acc: 0.2694\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4942 - acc: 0.5245 - val_loss: 2.8459 - val_acc: 0.2655\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 1.4718 - acc: 0.5302 - val_loss: 2.8531 - val_acc: 0.2603\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4612 - acc: 0.5267 - val_loss: 2.8392 - val_acc: 0.2679\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4439 - acc: 0.5379 - val_loss: 2.8663 - val_acc: 0.2642\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4578 - acc: 0.5294 - val_loss: 2.8624 - val_acc: 0.2643\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4390 - acc: 0.5382 - val_loss: 2.8596 - val_acc: 0.2651\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.4421 - acc: 0.5382 - val_loss: 2.8929 - val_acc: 0.2630\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4502 - acc: 0.5335 - val_loss: 2.8770 - val_acc: 0.2669\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4300 - acc: 0.5399 - val_loss: 2.9050 - val_acc: 0.2593\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4229 - acc: 0.5394 - val_loss: 2.8684 - val_acc: 0.2676\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4123 - acc: 0.5485 - val_loss: 2.8929 - val_acc: 0.2648\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4107 - acc: 0.5502 - val_loss: 2.9121 - val_acc: 0.2645\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.4196 - acc: 0.5485 - val_loss: 2.9118 - val_acc: 0.2640\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3955 - acc: 0.5549 - val_loss: 2.8965 - val_acc: 0.2653\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3922 - acc: 0.5517 - val_loss: 2.9200 - val_acc: 0.2619\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3903 - acc: 0.5532 - val_loss: 2.8982 - val_acc: 0.2603\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3904 - acc: 0.5517 - val_loss: 2.9136 - val_acc: 0.2622\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3579 - acc: 0.5711 - val_loss: 2.9209 - val_acc: 0.2624\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3700 - acc: 0.5580 - val_loss: 2.9284 - val_acc: 0.2586\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3718 - acc: 0.5612 - val_loss: 2.9232 - val_acc: 0.2596\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3648 - acc: 0.5616 - val_loss: 2.9505 - val_acc: 0.2578\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 1.3510 - acc: 0.5710 - val_loss: 2.9500 - val_acc: 0.2578\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3452 - acc: 0.5673 - val_loss: 2.9395 - val_acc: 0.2619\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3338 - acc: 0.5689 - val_loss: 2.9630 - val_acc: 0.2616\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3338 - acc: 0.5757 - val_loss: 2.9511 - val_acc: 0.2588\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3266 - acc: 0.5771 - val_loss: 2.9623 - val_acc: 0.2611\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3341 - acc: 0.5702 - val_loss: 2.9582 - val_acc: 0.2620\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3172 - acc: 0.5789 - val_loss: 2.9512 - val_acc: 0.2620\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3255 - acc: 0.5794 - val_loss: 2.9543 - val_acc: 0.2559\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.3042 - acc: 0.5831 - val_loss: 2.9848 - val_acc: 0.2638\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2958 - acc: 0.5869 - val_loss: 3.0018 - val_acc: 0.2573\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.3079 - acc: 0.5802 - val_loss: 2.9997 - val_acc: 0.2533\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2841 - acc: 0.5881 - val_loss: 2.9935 - val_acc: 0.2547\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2945 - acc: 0.5869 - val_loss: 2.9841 - val_acc: 0.2567\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2790 - acc: 0.5926 - val_loss: 2.9965 - val_acc: 0.2622\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2795 - acc: 0.5905 - val_loss: 3.0354 - val_acc: 0.2590\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2608 - acc: 0.5983 - val_loss: 2.9802 - val_acc: 0.2598\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2665 - acc: 0.5940 - val_loss: 3.0100 - val_acc: 0.2630\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2514 - acc: 0.5983 - val_loss: 3.0206 - val_acc: 0.2607\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 1.2491 - acc: 0.6021 - val_loss: 3.0145 - val_acc: 0.2565\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 1.2465 - acc: 0.6008 - val_loss: 3.0152 - val_acc: 0.2622\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 1.2529 - acc: 0.5995 - val_loss: 3.0071 - val_acc: 0.2614\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 1.2439 - acc: 0.6043 - val_loss: 3.0352 - val_acc: 0.2601\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 1.2264 - acc: 0.6057 - val_loss: 3.0323 - val_acc: 0.2576\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2372 - acc: 0.6095 - val_loss: 3.0443 - val_acc: 0.2612\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 1.2273 - acc: 0.6068 - val_loss: 2.9978 - val_acc: 0.2567\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.2244 - acc: 0.6044 - val_loss: 3.0551 - val_acc: 0.2614\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.2072 - acc: 0.6122 - val_loss: 3.0409 - val_acc: 0.2617\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.2029 - acc: 0.6111 - val_loss: 3.0542 - val_acc: 0.2575\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.2018 - acc: 0.6168 - val_loss: 3.0719 - val_acc: 0.2555\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.1961 - acc: 0.6153 - val_loss: 3.0492 - val_acc: 0.2568\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.1899 - acc: 0.6188 - val_loss: 3.0577 - val_acc: 0.2619\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 38ms/step - loss: 1.1854 - acc: 0.6197 - val_loss: 3.0691 - val_acc: 0.2585\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1861 - acc: 0.6196 - val_loss: 3.0818 - val_acc: 0.2572\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 1.1777 - acc: 0.6296 - val_loss: 3.1017 - val_acc: 0.2570\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1699 - acc: 0.6264 - val_loss: 3.0586 - val_acc: 0.2567\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1655 - acc: 0.6308 - val_loss: 3.1058 - val_acc: 0.2555\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1625 - acc: 0.6291 - val_loss: 3.1129 - val_acc: 0.2555\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1563 - acc: 0.6309 - val_loss: 3.0901 - val_acc: 0.2637\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1518 - acc: 0.6269 - val_loss: 3.1221 - val_acc: 0.2601\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1512 - acc: 0.6354 - val_loss: 3.0921 - val_acc: 0.2576\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1380 - acc: 0.6355 - val_loss: 3.1177 - val_acc: 0.2588\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1384 - acc: 0.6359 - val_loss: 3.1442 - val_acc: 0.2604\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1268 - acc: 0.6401 - val_loss: 3.1252 - val_acc: 0.2578\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1249 - acc: 0.6410 - val_loss: 3.1171 - val_acc: 0.2612\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1174 - acc: 0.6448 - val_loss: 3.1081 - val_acc: 0.2581\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1140 - acc: 0.6467 - val_loss: 3.1157 - val_acc: 0.2619\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1136 - acc: 0.6482 - val_loss: 3.1344 - val_acc: 0.2580\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1029 - acc: 0.6487 - val_loss: 3.1041 - val_acc: 0.2651\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 1.0948 - acc: 0.6535 - val_loss: 3.1405 - val_acc: 0.2572\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.1075 - acc: 0.6488 - val_loss: 3.1499 - val_acc: 0.2673\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0933 - acc: 0.6508 - val_loss: 3.1556 - val_acc: 0.2614\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0886 - acc: 0.6564 - val_loss: 3.1663 - val_acc: 0.2612\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0815 - acc: 0.6555 - val_loss: 3.1642 - val_acc: 0.2585\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0805 - acc: 0.6557 - val_loss: 3.1656 - val_acc: 0.2594\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0715 - acc: 0.6549 - val_loss: 3.1788 - val_acc: 0.2594\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0777 - acc: 0.6615 - val_loss: 3.1805 - val_acc: 0.2638\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0699 - acc: 0.6576 - val_loss: 3.2160 - val_acc: 0.2565\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0594 - acc: 0.6638 - val_loss: 3.2042 - val_acc: 0.2599\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0545 - acc: 0.6656 - val_loss: 3.2018 - val_acc: 0.2580\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0421 - acc: 0.6674 - val_loss: 3.1819 - val_acc: 0.2586\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 1.0588 - acc: 0.6607 - val_loss: 3.2101 - val_acc: 0.2590\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0392 - acc: 0.6689 - val_loss: 3.2232 - val_acc: 0.2596\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0276 - acc: 0.6728 - val_loss: 3.2152 - val_acc: 0.2633\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0327 - acc: 0.6704 - val_loss: 3.2275 - val_acc: 0.2550\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0175 - acc: 0.6770 - val_loss: 3.2348 - val_acc: 0.2568\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0258 - acc: 0.6744 - val_loss: 3.2434 - val_acc: 0.2598\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0191 - acc: 0.6759 - val_loss: 3.2466 - val_acc: 0.2581\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0277 - acc: 0.6752 - val_loss: 3.2198 - val_acc: 0.2627\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0027 - acc: 0.6798 - val_loss: 3.2510 - val_acc: 0.2578\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 1.0102 - acc: 0.6786 - val_loss: 3.2340 - val_acc: 0.2580\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9944 - acc: 0.6812 - val_loss: 3.2613 - val_acc: 0.2627\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9948 - acc: 0.6892 - val_loss: 3.2595 - val_acc: 0.2565\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9912 - acc: 0.6878 - val_loss: 3.2753 - val_acc: 0.2573\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9845 - acc: 0.6833 - val_loss: 3.3026 - val_acc: 0.2539\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9746 - acc: 0.6921 - val_loss: 3.2696 - val_acc: 0.2570\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9712 - acc: 0.6920 - val_loss: 3.2853 - val_acc: 0.2603\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9700 - acc: 0.6910 - val_loss: 3.2963 - val_acc: 0.2568\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9713 - acc: 0.6918 - val_loss: 3.2981 - val_acc: 0.2580\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9682 - acc: 0.6957 - val_loss: 3.3086 - val_acc: 0.2596\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9703 - acc: 0.6908 - val_loss: 3.2757 - val_acc: 0.2550\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9710 - acc: 0.6908 - val_loss: 3.3484 - val_acc: 0.2542\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9531 - acc: 0.6982 - val_loss: 3.3181 - val_acc: 0.2624\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9455 - acc: 0.6968 - val_loss: 3.2992 - val_acc: 0.2557\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9497 - acc: 0.6996 - val_loss: 3.3263 - val_acc: 0.2534\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9423 - acc: 0.7009 - val_loss: 3.3485 - val_acc: 0.2555\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.9390 - acc: 0.7001 - val_loss: 3.3445 - val_acc: 0.2557\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9253 - acc: 0.7093 - val_loss: 3.3169 - val_acc: 0.2583\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.9178 - acc: 0.7084 - val_loss: 3.3357 - val_acc: 0.2549\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.9212 - acc: 0.7039 - val_loss: 3.3530 - val_acc: 0.2557\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.9356 - acc: 0.7030 - val_loss: 3.3504 - val_acc: 0.2567\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9161 - acc: 0.7048 - val_loss: 3.3340 - val_acc: 0.2576\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9181 - acc: 0.7087 - val_loss: 3.3554 - val_acc: 0.2563\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9100 - acc: 0.7101 - val_loss: 3.3162 - val_acc: 0.2588\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.9243 - acc: 0.7087 - val_loss: 3.3864 - val_acc: 0.2550\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8920 - acc: 0.7200 - val_loss: 3.3923 - val_acc: 0.2580\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8939 - acc: 0.7183 - val_loss: 3.4073 - val_acc: 0.2575\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8993 - acc: 0.7150 - val_loss: 3.4066 - val_acc: 0.2555\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8944 - acc: 0.7177 - val_loss: 3.4206 - val_acc: 0.2520\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8880 - acc: 0.7190 - val_loss: 3.4031 - val_acc: 0.2580\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.8836 - acc: 0.7283 - val_loss: 3.4041 - val_acc: 0.2539\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.8702 - acc: 0.7257 - val_loss: 3.4161 - val_acc: 0.2581\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8772 - acc: 0.7222 - val_loss: 3.4049 - val_acc: 0.2572\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.8666 - acc: 0.7263 - val_loss: 3.4230 - val_acc: 0.2568\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8650 - acc: 0.7246 - val_loss: 3.3842 - val_acc: 0.2630\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.8499 - acc: 0.7298 - val_loss: 3.4515 - val_acc: 0.2550\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8455 - acc: 0.7349 - val_loss: 3.4416 - val_acc: 0.2539\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8476 - acc: 0.7302 - val_loss: 3.4475 - val_acc: 0.2537\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.8473 - acc: 0.7280 - val_loss: 3.4595 - val_acc: 0.2534\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8529 - acc: 0.7329 - val_loss: 3.4441 - val_acc: 0.2590\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8662 - acc: 0.7276 - val_loss: 3.4561 - val_acc: 0.2536\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8536 - acc: 0.7312 - val_loss: 3.4672 - val_acc: 0.2542\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8439 - acc: 0.7327 - val_loss: 3.4611 - val_acc: 0.2492\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8340 - acc: 0.7340 - val_loss: 3.4617 - val_acc: 0.2544\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8347 - acc: 0.7393 - val_loss: 3.4279 - val_acc: 0.2528\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8267 - acc: 0.7405 - val_loss: 3.4487 - val_acc: 0.2520\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.8289 - acc: 0.7378 - val_loss: 3.4867 - val_acc: 0.2503\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.8259 - acc: 0.7395 - val_loss: 3.4855 - val_acc: 0.2612\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.8192 - acc: 0.7424 - val_loss: 3.4624 - val_acc: 0.2555\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8183 - acc: 0.7420 - val_loss: 3.4999 - val_acc: 0.2533\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.8100 - acc: 0.7469 - val_loss: 3.4777 - val_acc: 0.2503\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.8108 - acc: 0.7438 - val_loss: 3.5303 - val_acc: 0.2549\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7972 - acc: 0.7475 - val_loss: 3.5081 - val_acc: 0.2555\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8004 - acc: 0.7431 - val_loss: 3.5234 - val_acc: 0.2563\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.8048 - acc: 0.7485 - val_loss: 3.5118 - val_acc: 0.2537\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7986 - acc: 0.7481 - val_loss: 3.5596 - val_acc: 0.2533\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7878 - acc: 0.7549 - val_loss: 3.5510 - val_acc: 0.2485\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.7894 - acc: 0.7486 - val_loss: 3.5445 - val_acc: 0.2562\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7847 - acc: 0.7503 - val_loss: 3.5793 - val_acc: 0.2524\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7800 - acc: 0.7517 - val_loss: 3.5811 - val_acc: 0.2516\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.7775 - acc: 0.7534 - val_loss: 3.5770 - val_acc: 0.2482\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.7760 - acc: 0.7557 - val_loss: 3.6071 - val_acc: 0.2508\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7728 - acc: 0.7558 - val_loss: 3.5850 - val_acc: 0.2498\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7696 - acc: 0.7592 - val_loss: 3.5795 - val_acc: 0.2492\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7699 - acc: 0.7510 - val_loss: 3.5520 - val_acc: 0.2555\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7569 - acc: 0.7589 - val_loss: 3.5631 - val_acc: 0.2505\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7473 - acc: 0.7643 - val_loss: 3.5925 - val_acc: 0.2502\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7615 - acc: 0.7557 - val_loss: 3.5994 - val_acc: 0.2552\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7552 - acc: 0.7624 - val_loss: 3.5911 - val_acc: 0.2557\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.7577 - acc: 0.7610 - val_loss: 3.6369 - val_acc: 0.2482\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7453 - acc: 0.7592 - val_loss: 3.6368 - val_acc: 0.2497\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7469 - acc: 0.7626 - val_loss: 3.6278 - val_acc: 0.2557\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7334 - acc: 0.7718 - val_loss: 3.6414 - val_acc: 0.2544\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7350 - acc: 0.7661 - val_loss: 3.6210 - val_acc: 0.2526\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7350 - acc: 0.7653 - val_loss: 3.6345 - val_acc: 0.2480\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7349 - acc: 0.7669 - val_loss: 3.6327 - val_acc: 0.2552\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.7238 - acc: 0.7713 - val_loss: 3.6729 - val_acc: 0.2487\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7322 - acc: 0.7668 - val_loss: 3.6649 - val_acc: 0.2495\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7245 - acc: 0.7709 - val_loss: 3.6649 - val_acc: 0.2502\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.7231 - acc: 0.7738 - val_loss: 3.6605 - val_acc: 0.2552\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7155 - acc: 0.7786 - val_loss: 3.6704 - val_acc: 0.2498\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7158 - acc: 0.7751 - val_loss: 3.6861 - val_acc: 0.2552\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.7157 - acc: 0.7739 - val_loss: 3.6842 - val_acc: 0.2550\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6997 - acc: 0.7747 - val_loss: 3.6819 - val_acc: 0.2526\n",
      "Epoch 367/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7028 - acc: 0.7802 - val_loss: 3.7184 - val_acc: 0.2505\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7110 - acc: 0.7747 - val_loss: 3.6953 - val_acc: 0.2508\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7007 - acc: 0.7770 - val_loss: 3.6932 - val_acc: 0.2539\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.7004 - acc: 0.7773 - val_loss: 3.6774 - val_acc: 0.2557\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6956 - acc: 0.7788 - val_loss: 3.6968 - val_acc: 0.2498\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6968 - acc: 0.7808 - val_loss: 3.7259 - val_acc: 0.2524\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6910 - acc: 0.7846 - val_loss: 3.6657 - val_acc: 0.2591\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6833 - acc: 0.7872 - val_loss: 3.7134 - val_acc: 0.2533\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6887 - acc: 0.7831 - val_loss: 3.7517 - val_acc: 0.2541\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6813 - acc: 0.7846 - val_loss: 3.7636 - val_acc: 0.2523\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6805 - acc: 0.7795 - val_loss: 3.7451 - val_acc: 0.2520\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6700 - acc: 0.7850 - val_loss: 3.6909 - val_acc: 0.2559\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.6883 - acc: 0.7826 - val_loss: 3.7462 - val_acc: 0.2490\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6788 - acc: 0.7870 - val_loss: 3.7630 - val_acc: 0.2523\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6721 - acc: 0.7859 - val_loss: 3.7656 - val_acc: 0.2507\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6638 - acc: 0.7937 - val_loss: 3.7614 - val_acc: 0.2505\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6764 - acc: 0.7867 - val_loss: 3.7737 - val_acc: 0.2484\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6615 - acc: 0.7848 - val_loss: 3.7912 - val_acc: 0.2495\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6606 - acc: 0.7904 - val_loss: 3.7963 - val_acc: 0.2471\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6590 - acc: 0.7932 - val_loss: 3.8055 - val_acc: 0.2513\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6529 - acc: 0.7940 - val_loss: 3.8086 - val_acc: 0.2547\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6472 - acc: 0.7986 - val_loss: 3.8028 - val_acc: 0.2531\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6504 - acc: 0.7934 - val_loss: 3.8337 - val_acc: 0.2482\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.6529 - acc: 0.7921 - val_loss: 3.8013 - val_acc: 0.2537\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.6520 - acc: 0.7917 - val_loss: 3.7776 - val_acc: 0.2505\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.6446 - acc: 0.7953 - val_loss: 3.8415 - val_acc: 0.2485\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.6444 - acc: 0.7976 - val_loss: 3.8147 - val_acc: 0.2489\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6317 - acc: 0.8034 - val_loss: 3.7983 - val_acc: 0.2489\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6302 - acc: 0.8005 - val_loss: 3.8169 - val_acc: 0.2466\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6376 - acc: 0.8010 - val_loss: 3.8543 - val_acc: 0.2482\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6319 - acc: 0.8005 - val_loss: 3.8211 - val_acc: 0.2505\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.6275 - acc: 0.8010 - val_loss: 3.8483 - val_acc: 0.2476\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6331 - acc: 0.8005 - val_loss: 3.8266 - val_acc: 0.2471\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6195 - acc: 0.8019 - val_loss: 3.8696 - val_acc: 0.2459\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.6266 - acc: 0.8035 - val_loss: 3.8713 - val_acc: 0.2529\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6125 - acc: 0.8057 - val_loss: 3.9007 - val_acc: 0.2497\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.6220 - acc: 0.8034 - val_loss: 3.8637 - val_acc: 0.2502\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6133 - acc: 0.8065 - val_loss: 3.8801 - val_acc: 0.2534\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6071 - acc: 0.8086 - val_loss: 3.8694 - val_acc: 0.2539\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6087 - acc: 0.8052 - val_loss: 3.9089 - val_acc: 0.2480\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6121 - acc: 0.8022 - val_loss: 3.8996 - val_acc: 0.2493\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6045 - acc: 0.8071 - val_loss: 3.9198 - val_acc: 0.2511\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6120 - acc: 0.8029 - val_loss: 3.9007 - val_acc: 0.2502\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6013 - acc: 0.8089 - val_loss: 3.9381 - val_acc: 0.2492\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6012 - acc: 0.8098 - val_loss: 3.9261 - val_acc: 0.2479\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5904 - acc: 0.8175 - val_loss: 3.9115 - val_acc: 0.2446\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.5946 - acc: 0.8072 - val_loss: 3.9506 - val_acc: 0.2492\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5930 - acc: 0.8104 - val_loss: 3.9581 - val_acc: 0.2453\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.5913 - acc: 0.8094 - val_loss: 3.9294 - val_acc: 0.2490\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.5893 - acc: 0.8144 - val_loss: 3.9228 - val_acc: 0.2516\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5866 - acc: 0.8156 - val_loss: 3.9200 - val_acc: 0.2497\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5834 - acc: 0.8132 - val_loss: 3.9712 - val_acc: 0.2493\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5907 - acc: 0.8098 - val_loss: 4.0080 - val_acc: 0.2492\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5859 - acc: 0.8103 - val_loss: 3.9919 - val_acc: 0.2487\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5761 - acc: 0.8181 - val_loss: 3.9783 - val_acc: 0.2493\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5700 - acc: 0.8152 - val_loss: 3.9812 - val_acc: 0.2500\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.5844 - acc: 0.8161 - val_loss: 3.9793 - val_acc: 0.2511\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.5740 - acc: 0.8187 - val_loss: 4.0010 - val_acc: 0.2490\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.5735 - acc: 0.8170 - val_loss: 3.9988 - val_acc: 0.2503\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.5787 - acc: 0.8174 - val_loss: 4.0064 - val_acc: 0.2467\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.5702 - acc: 0.8189 - val_loss: 3.9921 - val_acc: 0.2485\n",
      "Epoch 428/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 46ms/step - loss: 0.5693 - acc: 0.8205 - val_loss: 4.0107 - val_acc: 0.2482\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.5617 - acc: 0.8220 - val_loss: 3.9991 - val_acc: 0.2472\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5650 - acc: 0.8210 - val_loss: 4.0192 - val_acc: 0.2448\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.5637 - acc: 0.8174 - val_loss: 4.0337 - val_acc: 0.2507\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5599 - acc: 0.8212 - val_loss: 3.9867 - val_acc: 0.2555\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5623 - acc: 0.8203 - val_loss: 4.0585 - val_acc: 0.2453\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.5529 - acc: 0.8232 - val_loss: 4.0189 - val_acc: 0.2474\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.5601 - acc: 0.8213 - val_loss: 4.0878 - val_acc: 0.2500\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5576 - acc: 0.8216 - val_loss: 4.0364 - val_acc: 0.2528\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5487 - acc: 0.8245 - val_loss: 4.0385 - val_acc: 0.2497\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5563 - acc: 0.8212 - val_loss: 4.0412 - val_acc: 0.2466\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5495 - acc: 0.8244 - val_loss: 4.0508 - val_acc: 0.2471\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5334 - acc: 0.8273 - val_loss: 4.0524 - val_acc: 0.2428\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5375 - acc: 0.8313 - val_loss: 4.0545 - val_acc: 0.2446\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5394 - acc: 0.8266 - val_loss: 4.0988 - val_acc: 0.2432\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5335 - acc: 0.8324 - val_loss: 4.0674 - val_acc: 0.2458\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5361 - acc: 0.8302 - val_loss: 4.0720 - val_acc: 0.2476\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.5308 - acc: 0.8333 - val_loss: 4.1137 - val_acc: 0.2456\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5251 - acc: 0.8324 - val_loss: 4.0675 - val_acc: 0.2520\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5232 - acc: 0.8333 - val_loss: 4.1055 - val_acc: 0.2520\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5298 - acc: 0.8336 - val_loss: 4.1355 - val_acc: 0.2476\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5342 - acc: 0.8299 - val_loss: 4.0618 - val_acc: 0.2524\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5280 - acc: 0.8311 - val_loss: 4.1335 - val_acc: 0.2437\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5199 - acc: 0.8345 - val_loss: 4.0961 - val_acc: 0.2412\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5233 - acc: 0.8327 - val_loss: 4.1659 - val_acc: 0.2477\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5244 - acc: 0.8340 - val_loss: 4.1459 - val_acc: 0.2437\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5260 - acc: 0.8328 - val_loss: 4.1679 - val_acc: 0.2430\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5149 - acc: 0.8336 - val_loss: 4.1360 - val_acc: 0.2467\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5263 - acc: 0.8309 - val_loss: 4.1265 - val_acc: 0.2521\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5144 - acc: 0.8397 - val_loss: 4.1313 - val_acc: 0.2480\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.5095 - acc: 0.8395 - val_loss: 4.1955 - val_acc: 0.2427\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5192 - acc: 0.8326 - val_loss: 4.1590 - val_acc: 0.2446\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5149 - acc: 0.8355 - val_loss: 4.1482 - val_acc: 0.2443\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5105 - acc: 0.8340 - val_loss: 4.1534 - val_acc: 0.2420\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5102 - acc: 0.8354 - val_loss: 4.1935 - val_acc: 0.2451\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5102 - acc: 0.8366 - val_loss: 4.1944 - val_acc: 0.2450\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5118 - acc: 0.8387 - val_loss: 4.2117 - val_acc: 0.2437\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5027 - acc: 0.8378 - val_loss: 4.1766 - val_acc: 0.2484\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5067 - acc: 0.8398 - val_loss: 4.1652 - val_acc: 0.2485\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.5015 - acc: 0.8400 - val_loss: 4.2054 - val_acc: 0.2487\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.5045 - acc: 0.8372 - val_loss: 4.1999 - val_acc: 0.2472\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4971 - acc: 0.8401 - val_loss: 4.1808 - val_acc: 0.2482\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4948 - acc: 0.8440 - val_loss: 4.2302 - val_acc: 0.2415\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.4947 - acc: 0.8411 - val_loss: 4.2230 - val_acc: 0.2482\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4966 - acc: 0.8429 - val_loss: 4.2475 - val_acc: 0.2437\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.4957 - acc: 0.8435 - val_loss: 4.2194 - val_acc: 0.2445\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4917 - acc: 0.8415 - val_loss: 4.2391 - val_acc: 0.2474\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4919 - acc: 0.8443 - val_loss: 4.2441 - val_acc: 0.2456\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4863 - acc: 0.8411 - val_loss: 4.2814 - val_acc: 0.2463\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4895 - acc: 0.8450 - val_loss: 4.2438 - val_acc: 0.2467\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4804 - acc: 0.8429 - val_loss: 4.2791 - val_acc: 0.2422\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4892 - acc: 0.8423 - val_loss: 4.2237 - val_acc: 0.2456\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4838 - acc: 0.8465 - val_loss: 4.2145 - val_acc: 0.2445\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4721 - acc: 0.8489 - val_loss: 4.2706 - val_acc: 0.2433\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4875 - acc: 0.8438 - val_loss: 4.2469 - val_acc: 0.2454\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4778 - acc: 0.8492 - val_loss: 4.3092 - val_acc: 0.2394\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4809 - acc: 0.8434 - val_loss: 4.2652 - val_acc: 0.2466\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4804 - acc: 0.8473 - val_loss: 4.3115 - val_acc: 0.2432\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4713 - acc: 0.8513 - val_loss: 4.2747 - val_acc: 0.2448\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4704 - acc: 0.8477 - val_loss: 4.2210 - val_acc: 0.2500\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4717 - acc: 0.8497 - val_loss: 4.3090 - val_acc: 0.2464\n",
      "Epoch 489/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4742 - acc: 0.8478 - val_loss: 4.3101 - val_acc: 0.2443\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4745 - acc: 0.8481 - val_loss: 4.2743 - val_acc: 0.2484\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4703 - acc: 0.8490 - val_loss: 4.2933 - val_acc: 0.2427\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4695 - acc: 0.8495 - val_loss: 4.3047 - val_acc: 0.2437\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.4753 - acc: 0.8455 - val_loss: 4.3095 - val_acc: 0.2437\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4685 - acc: 0.8491 - val_loss: 4.3306 - val_acc: 0.2422\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4618 - acc: 0.8496 - val_loss: 4.3531 - val_acc: 0.2414\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4604 - acc: 0.8527 - val_loss: 4.3457 - val_acc: 0.2450\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.4586 - acc: 0.8530 - val_loss: 4.3686 - val_acc: 0.2467\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4613 - acc: 0.8547 - val_loss: 4.3726 - val_acc: 0.2448\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.4642 - acc: 0.8492 - val_loss: 4.3843 - val_acc: 0.2440\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.4670 - acc: 0.8481 - val_loss: 4.3632 - val_acc: 0.2445\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='48.016 MB of 48.016 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.84882</td></tr><tr><td>best_epoch</td><td>84</td></tr><tr><td>best_val_loss</td><td>2.50486</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.4657</td></tr><tr><td>val_acc</td><td>0.24447</td></tr><tr><td>val_loss</td><td>4.36322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">likely-feather-105</strong>: <a href=\"https://wandb.ai/tku-cilab/lstm-singletrack-js-fake/runs/20g5tg1s\" target=\"_blank\">https://wandb.ai/tku-cilab/lstm-singletrack-js-fake/runs/20g5tg1s</a><br/>Synced 6 W&B file(s), 16 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220627_180421-20g5tg1s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.init(config=params, project='lstm-singletrack-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(trainDatasets[track], validation_data=testDatasets[track], batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n",
    "\n",
    "if outputs['wandb']:\n",
    "    hist = np.histogram(trainData[track], bins=params['vocab_size'][track])\n",
    "    topkWords = tf.math.top_k(hist[0], 10)\n",
    "    topkChoicesWords = topkWords[1].numpy().squeeze()\n",
    "    topkValuesWords = topkWords[0].numpy().squeeze()\n",
    "\n",
    "    weight = model.get_weights()\n",
    "    model2 = makeSingleTrackModel(track, 1)\n",
    "    model2.set_weights(weight)\n",
    "\n",
    "    model2.build(tf.TensorShape([1, None]))\n",
    "    for index, idx in enumerate(topkChoicesWords):\n",
    "        beat = idx2beat[track][idx]\n",
    "\n",
    "        model2.reset_states()\n",
    "        pred = model2(np.array([[idx]]))\n",
    "\n",
    "        p = pred.numpy().squeeze()\n",
    "\n",
    "        x_values = list(range(0, params['vocab_size'][track]))\n",
    "\n",
    "        data = [[x, y] for (x, y) in zip(x_values, p)]\n",
    "        table = wandb.Table(data=data, columns = [\"idx\", \"prob\"])\n",
    "        wandb.log({f\"softmax_distribution_top{index+1}\" : wandb.plot.line(table, \"idx\", \"prob\",\n",
    "                   title=f\"Top {index+1} : {idx2beat[track][idx]} Softmax Prob Distribution\")})\n",
    "\n",
    "    for i in range(params['track_size']):\n",
    "        x_values = list(range(0, params['vocab_size'][i]))\n",
    "        hist = np.histogram(trainData[i], bins=params['vocab_size'][i])\n",
    "        data = [[x, y] for (x, y) in zip(x_values, hist[0].tolist())]\n",
    "        table = wandb.Table(data=data, columns = [\"idx\", \"occurence\"])\n",
    "        wandb.log({f'word_distribution_track_{i}' : wandb.plot.line(table, \"idx\", \"occurence\",\n",
    "                   title=f\"Track {i} Word distribution.\")})\n",
    "    \n",
    "    wandb.log({'model_architecture': wandb.Image(name+'.png')})\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[296, 635, 813, 545]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for track in range(params['track_size']):\n",
    "\n",
    "    x = list(trainDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    y = list(trainDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    val_x = list(testDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    val_y = list(testDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "    x_val.append(val_x)\n",
    "    y_val.append(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape, y_train[0].shape, x_val[0].shape, y_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'multi-track-lstm-training-5'\n",
    "model = makeMultiTrackModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.init(config=params, project='lstm-multi-track-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n",
    "\n",
    "if outputs['wandb']:\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Single Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = np.array([trainData[0, initBeatIndex:initBeatIndex+params['sequence_length']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 'model-single-track-lstm-training-05-4.0770.hdf5'\n",
    "\n",
    "model = makeSingleTrackModel(track, 1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = pred.numpy().squeeze()\n",
    "\n",
    "music_sequence = []\n",
    "\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    topk = tf.math.top_k(pred[-1], 3)\n",
    "    topkChoices = topk[1].numpy().squeeze()\n",
    "    topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "    # Apply random\n",
    "    next_beat = None\n",
    "    if np.random.uniform(0, 1) < .5:\n",
    "        next_beat = topkChoices[0]\n",
    "    else:\n",
    "        p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "        next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "    music_sequence.append(idx2beat[track][next_beat])\n",
    "\n",
    "    pred = model(np.array([[next_beat]]))\n",
    "    pred = tf.expand_dims(pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi(name+'.mid', [music_sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Multi Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = []\n",
    "for track in range(params['track_size']):\n",
    "    initBeat.append(np.array([trainData[track, initBeatIndex:initBeatIndex+params['sequence_length']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 'model-multi-track-lstm-training-4-998-1.0914.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeMultiTrackModel(1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = [p.numpy().squeeze() for p in pred]\n",
    "\n",
    "music_sequence = []\n",
    "for track in range(params['track_size']):\n",
    "    music_sequence.append([idx2beat[track][idx] for idx in initBeat[track][0].tolist()])\n",
    "\n",
    "outputs['length'] = 100\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    nextBeatList = []\n",
    "    for index, p in enumerate(pred):\n",
    "        topk = tf.math.top_k(p[-1], 3)\n",
    "        topkChoices = topk[1].numpy().squeeze()\n",
    "        topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "        # Apply random\n",
    "        # next_beat = topkChoices[0]\n",
    "        next_beat = None\n",
    "        if np.random.uniform(0, 1) < .5:\n",
    "            next_beat = topkChoices[0]\n",
    "        else:\n",
    "            p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "            next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "        music_sequence[index].append(idx2beat[index][next_beat])\n",
    "        nextBeatList.append(np.array([[next_beat]]))\n",
    "\n",
    "    pred = model.predict(nextBeatList, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi('new100-4-2'+'.mid', music_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model(model, to_file=name+'.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42d6b00596c858df57cfb1e3d56019ad36764fdda4c39cb12fa72d6aaee7c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
