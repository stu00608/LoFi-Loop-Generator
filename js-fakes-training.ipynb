{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Embedding, Dropout, concatenate, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "config = yaml.safe_load(open('config.yaml', 'r'))\n",
    "pathes = config['path']\n",
    "params = config['params']\n",
    "outputs = config['output']\n",
    "params['beat_duration'] = 1/(params['bpm']/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteData(pretty_midi.Note):\n",
    "\n",
    "    def __init__(self, velocity, pitch, start, end, sustain):\n",
    "        super().__init__(velocity, pitch, start, end)\n",
    "        self.sustain = 1 if sustain else 0\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(data, start, velocity=90):\n",
    "        '''\n",
    "        Return (`pretty_midi.Note`, sustain)\n",
    "        '''\n",
    "        data = data.split('-')\n",
    "        pitch = int(data[0])\n",
    "        duration = float(data[1])\n",
    "        end = start+duration\n",
    "\n",
    "        return pretty_midi.Note(velocity, pitch, start, end), int(data[2])\n",
    "\n",
    "    def encode(self):\n",
    "        return f'{self.pitch}-{self.get_duration()}-{self.sustain}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        # return f'Note(start={self.start}, end={self.end}, pitch={self.pitch}, velocity={self.velocity}, sustain={self.sustain})'\n",
    "        return f'NoteData(pitch={self.pitch}, duration={self.get_duration()}, sustain={self.sustain}, enc={self.encode()})'\n",
    "\n",
    "\n",
    "def checkIntervals(beat: List[NoteData], start: float, end: float):\n",
    "    '''\n",
    "    Pass a list of encoded beat string. Returns a list of note off intervals.\n",
    "    '''\n",
    "\n",
    "    beat = beat.copy()\n",
    "    beat.insert(0, NoteData(90, 0, None, start, 1))\n",
    "    beat.append(NoteData(90, 0, end, None, 1))\n",
    "    intervals = []\n",
    "    for i in range(1, len(beat)):\n",
    "        note_time_interval = beat[i].start-beat[i-1].end\n",
    "        if(note_time_interval > 0):\n",
    "            intervals.append([beat[i-1].end, beat[i].start])\n",
    "        elif(note_time_interval < 0):\n",
    "            print(\"Error! Minus note interval, is there any overlapping note exist?\")\n",
    "\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def expandNoteList(notes):\n",
    "\n",
    "    # First note on time, in second\n",
    "    midiStartTime = notes[0].start\n",
    "    # Last note off time, in second\n",
    "    midiEndTime = notes[-1].end\n",
    "    # How many beats in this note list. One in 4/4.\n",
    "    beatNum = int((midiEndTime-midiStartTime)/params['beat_duration'])\n",
    "\n",
    "    lastPitch = None\n",
    "    totalNoteDataList = []\n",
    "    for beatIndex in range(beatNum):\n",
    "        # Get start and end time in this beat.\n",
    "        start = midiStartTime + beatIndex*params['beat_duration']\n",
    "        end = midiStartTime + (beatIndex+1)*params['beat_duration']\n",
    "\n",
    "        # Find notes that cover this beat interval.\n",
    "        coveredNotes = [note for note in notes if (note.start < end)]\n",
    "        coveredNotes = [note for note in coveredNotes if (note.end > start)]\n",
    "\n",
    "        # encodedBeatList = []\n",
    "        noteDataList = []\n",
    "        for note in coveredNotes:\n",
    "            sustain = (note.pitch != lastPitch or note.start < start)\n",
    "\n",
    "            # Clip the note start and end time.\n",
    "            noteStart = start if note.start <= start else note.start\n",
    "            noteEnd = end if note.end >= end else note.end\n",
    "\n",
    "            # Add a new NoteData object to the list.\n",
    "            noteData = NoteData(90, note.pitch, noteStart, noteEnd, sustain)\n",
    "            noteDataList.append(noteData)\n",
    "            lastPitch = note.pitch\n",
    "\n",
    "        # Check if there is any interval between notes, cause it won't count\n",
    "        # any note off intervals as a Note.\n",
    "        intervals = checkIntervals(noteDataList, start, end)\n",
    "        if intervals:\n",
    "            for interval in intervals:\n",
    "                # We add a pitch 0 Note object to mark as rest.\n",
    "                noteData = NoteData(90, 0, interval[0], interval[1], 1)\n",
    "                noteDataList.append(noteData)\n",
    "\n",
    "        # Sort the list base on start time, so the list will stay as time series.\n",
    "        noteDataList.sort(key=lambda x: x.start)\n",
    "\n",
    "        totalNoteDataList.append(noteDataList)\n",
    "\n",
    "    return totalNoteDataList\n",
    "\n",
    "\n",
    "def encodeExpandedNoteList(expandedNoteDataList: List[List[NoteData]]):\n",
    "    '''\n",
    "    Takes the expanded note list and encode each NoteData object.\n",
    "\n",
    "    Returns a dataset ready encoded note representation.\n",
    "    '''\n",
    "    encodedBeatList = []\n",
    "    for expandedNoteData in expandedNoteDataList:\n",
    "        encodedBeatList.append('#'.join([noteData.encode() for noteData in expandedNoteData]))\n",
    "    return encodedBeatList\n",
    "\n",
    "\n",
    "def decodeBeatList(encodedBeatList):\n",
    "    '''\n",
    "    Decode beat from encoded music sequence. \n",
    "\n",
    "    Returns note list that can use in `pretty_midi.Instrument.notes`.\n",
    "    '''\n",
    "\n",
    "    timestamp = 0\n",
    "    decodedNoteDataList = []\n",
    "    for beat in encodedBeatList:\n",
    "        encodedNotes = beat.split('#')\n",
    "        for encodedNote in encodedNotes:\n",
    "            decodedNote, sustain = NoteData.decode(encodedNote, timestamp)\n",
    "            decodedNoteDataList.append((decodedNote, sustain))\n",
    "            timestamp += decodedNote.get_duration()\n",
    "\n",
    "    decodedNoteList = []\n",
    "    lastPitchAndSustain = (-1, -1)\n",
    "    for decodedNote, sustain in decodedNoteDataList:\n",
    "        if decodedNote.pitch == 0:\n",
    "            pass\n",
    "        elif decodedNote.pitch == lastPitchAndSustain[0] and sustain:\n",
    "            decodedNoteList[-1].end = decodedNote.end\n",
    "        else:\n",
    "            decodedNoteList.append(decodedNote)\n",
    "\n",
    "        lastPitchAndSustain = (decodedNote.pitch, sustain)\n",
    "\n",
    "    return decodedNoteList\n",
    "\n",
    "\n",
    "def generateMidi(filename: str, tracks: List[List[str]], programName: str = 'Acoustic Grand Piano'):\n",
    "    '''\n",
    "    tracks `List[List[str]]`:\n",
    "        Encoded beat sequence. [['70-0.5-1', '68-0.25-1#70-0.25-1'..], ...]\n",
    "\n",
    "    Write the midi file from encoded tracks.\n",
    "\n",
    "    '''\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    for index, track in enumerate(tracks):\n",
    "        _instrument = pretty_midi.Instrument(\n",
    "            pretty_midi.instrument_name_to_program(programName), False, f\"Track {index+1}\")\n",
    "        _instrument.pitch_bends.append(pretty_midi.PitchBend(0, 0))\n",
    "        _instrument.notes = decodeBeatList(track)\n",
    "        midi.instruments.append(_instrument)\n",
    "\n",
    "    midi.write(filename)\n",
    "\n",
    "\n",
    "def loadMidiInFolder(path, pkl):\n",
    "    '''\n",
    "    path:\n",
    "        path for glob to grab midi. Must include last file name like `*.mid`.\n",
    "\n",
    "    Return tracks read from midi, Note has been encoded to string.\n",
    "    '''\n",
    "    wordsList = []\n",
    "    if os.path.exists(pkl):\n",
    "        with open(pkl, 'rb') as f:\n",
    "            wordsList = pickle.load(f)\n",
    "    else:\n",
    "        for mid in tqdm(glob(path, recursive=True)):\n",
    "            try:\n",
    "                midiData = pretty_midi.PrettyMIDI(mid)\n",
    "            except:\n",
    "                print(\"Cannot load this midi\")\n",
    "                continue\n",
    "\n",
    "            tracks = [instrument.notes for instrument in midiData.instruments]\n",
    "            encodedTracks = [encodeExpandedNoteList(expandNoteList(track)) for track in tracks]\n",
    "            wordsList.append(encodedTracks)\n",
    "        with open(pkl, 'wb') as f:\n",
    "            pickle.dump(wordsList, f)\n",
    "\n",
    "    return wordsList\n",
    "\n",
    "\n",
    "def concatMidi(data):\n",
    "    '''\n",
    "    data:\n",
    "        trainDataRaw or testDataRaw, will concatenate each track.\n",
    "\n",
    "    Returns np.array (4, total_length)\n",
    "    '''\n",
    "\n",
    "    concatData = None\n",
    "    for mid in data:\n",
    "        if concatData == None:\n",
    "            concatData = mid\n",
    "        else:\n",
    "            for i in range(len(concatData)):\n",
    "                concatData[i] += mid[i]\n",
    "\n",
    "    return np.array(concatData)\n",
    "\n",
    "\n",
    "def __split_input_target(chunk):\n",
    "    '''\n",
    "    Split x and y for training, in our case, x is the current word, y is the next word.\n",
    "    '''\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = tf.one_hot(chunk[1:], params['current_vocab_size'])\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "def makeDataset(data, track):\n",
    "    '''\n",
    "    data:\n",
    "        1-d list.\n",
    "    track:\n",
    "        specify the track number to get correct vocab_size.\n",
    "\n",
    "    Make a tf dataset from a 1-d array.\n",
    "\n",
    "    It will batch for `sequence_length` to split each sentence. \n",
    "    Then map it to x, y. Finally batch to the batch size we set.\n",
    "\n",
    "    Returns a BatchDataset.\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.batch(params['sequence_length']+1, drop_remainder=True)\n",
    "    params['current_vocab_size'] = params['vocab_size'][track]\n",
    "    dataset = dataset.map(__split_input_target)\n",
    "    del params['current_vocab_size']\n",
    "    dataset = dataset.shuffle(10000).batch(params['batch_size'], drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def makeSingleTrackModel(track, batch_size=params['batch_size']):\n",
    "    '''\n",
    "    Create `Model` object for single track training.\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(params['vocab_size'][track], output_dim=params['embed_size'],\n",
    "                        batch_input_shape=(batch_size, None)))\n",
    "    for _ in range(params['layers']):\n",
    "        model.add(LSTM(params['unit'], return_sequences=True, stateful=params['stateful'],\n",
    "                       dropout=params['dropout'], recurrent_dropout=params['dropout']))\n",
    "\n",
    "    model.add(Dense(params['unit'], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['vocab_size'][track], activation='softmax'))\n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=False),\n",
    "                  optimizer=Adam(learning_rate=0.0001), metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def makeLSTMLayer(name, track, batch_size=params['batch_size']):\n",
    "    '''\n",
    "    Make input embedding, LSTM layers of multi track model.\n",
    "    '''\n",
    "\n",
    "    inputLayer = Input(batch_input_shape=([batch_size, None]))\n",
    "    embedLayer = Embedding(params['vocab_size'][track],\n",
    "                           params['embed_size'], name=name+'-embed')(inputLayer)\n",
    "    lstmLayer = LSTM(params['unit'], return_sequences=True, stateful=params['stateful'],\n",
    "                     dropout=params['dropout'], recurrent_dropout=params['dropout'], name=name+'-LSTM1')(embedLayer)\n",
    "    lstmLayer = LSTM(params['unit'], return_sequences=True, stateful=params['stateful'],\n",
    "                     dropout=params['dropout'], recurrent_dropout=params['dropout'], name=name+'-LSTM2')(lstmLayer)\n",
    "\n",
    "    return inputLayer, lstmLayer\n",
    "\n",
    "\n",
    "def makeOutputLayer(name, layer, track):\n",
    "    '''\n",
    "    Make output combined linear dense layers of multi track model.\n",
    "    '''\n",
    "\n",
    "    outputLayer = layer\n",
    "    # outputLayer = Dense(params['unit'], activation='relu', name=name+'-linear2')(layer)\n",
    "    # outputLayer = BatchNormalization()(outputLayer)\n",
    "    # outputLayer = Dropout(params['dropout'])(outputLayer)\n",
    "    outputLayer = Dense(params['vocab_size'][track], activation='softmax',\n",
    "                        name=name+'-output')(outputLayer)\n",
    "\n",
    "    return outputLayer\n",
    "\n",
    "\n",
    "def makeMultiTrackModel(batch_size=params['batch_size']):\n",
    "    '''\n",
    "    Create `Model` object for multi track training. \n",
    "    '''\n",
    "\n",
    "    inputLayer1, lstmLayer1 = makeLSTMLayer('input1', 0, batch_size)\n",
    "    inputLayer2, lstmLayer2 = makeLSTMLayer('input2', 1, batch_size)\n",
    "    inputLayer3, lstmLayer3 = makeLSTMLayer('input3', 2, batch_size)\n",
    "    inputLayer4, lstmLayer4 = makeLSTMLayer('input4', 3, batch_size)\n",
    "\n",
    "    concatLayers = concatenate([lstmLayer1, lstmLayer2, lstmLayer3, lstmLayer4])\n",
    "\n",
    "    x = LSTM(params['unit'], return_sequences=True, name='concatLSTMLayer1')(concatLayers)\n",
    "    # x = Dropout(params['dropout'])(x)\n",
    "    # x = LSTM(params['unit'], return_sequences=True, name='concatLSTMLayer2')(x)\n",
    "    x = Dense(params['unit'], activation='relu', name='concatLinear1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(params['dropout'])(x)\n",
    "\n",
    "    outputLayers = [makeOutputLayer('output'+str(i), x, i) for i in range(params['track_size'])]\n",
    "\n",
    "    model = Model(inputs=[inputLayer1, inputLayer2, inputLayer3, inputLayer4], outputs=outputLayers)\n",
    "\n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=False),\n",
    "                  optimizer=Adam(learning_rate=0.0001), metrics=['acc'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRaw = loadMidiInFolder(pathes['data_dir'], 'data/trainDataRaw')\n",
    "testDataRaw = loadMidiInFolder(pathes['test_dir'], 'data/testDataRaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = concatMidi(trainDataRaw)\n",
    "testData = concatMidi(testDataRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for each track or collect all (now).\n",
    "\n",
    "beat2idx = []\n",
    "idx2beat = []\n",
    "params['vocab_size'] = []\n",
    "\n",
    "vocabularies = set()\n",
    "\n",
    "for track in range(len(trainData)):\n",
    "    vocabularies = vocabularies | set(trainData[track]) | set(testData[track])\n",
    "for track in range(len(trainData)):\n",
    "    params['vocab_size'].append(len(vocabularies))\n",
    "    beat2idx.append({beat: i for i, beat in enumerate(vocabularies)})\n",
    "    idx2beat.append({idx:beat for beat, idx in beat2idx[track].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1499, 1499, 1499, 1499]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in range(len(trainData)):\n",
    "\n",
    "    trainData[track] = np.array([beat2idx[track][beat] for beat in trainData[track]])\n",
    "    testData[track] = np.array([beat2idx[track][beat] for beat in testData[track]])\n",
    "\n",
    "trainData = trainData.astype(int)\n",
    "testData = testData.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasets = []\n",
    "testDatasets = []\n",
    "for track in range(len(trainData)):\n",
    "    trainDatasets.append(makeDataset(trainData[track], track))\n",
    "    testDatasets.append(makeDataset(testData[track], track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((16, 16), (16, 16, 1499)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "name = 'single-track-lstm-training'\n",
    "track = 0\n",
    "model = makeSingleTrackModel(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if config['output']['wandb']:\n",
    "    wandb.init(config=params, project='lstm-singletrack-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(trainDatasets[track], validation_data=testDatasets[track], batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi track training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for track in range(params['track_size']):\n",
    "\n",
    "    x = list(trainDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    y = list(trainDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    val_x = list(testDatasets[track].map(lambda x, y: x))[0].numpy()\n",
    "    val_y = list(testDatasets[track].map(lambda x, y: y))[0].numpy()\n",
    "\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "    x_val.append(val_x)\n",
    "    y_val.append(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 16, 1499), (16, 16), (16, 16, 1499))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape, y_train[0].shape, x_val[0].shape, y_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer input1-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input1-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input2-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input2-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input3-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input3-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input4-LSTM1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer input4-LSTM2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "name = 'multi-track-lstm-training-5'\n",
    "model = makeMultiTrackModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "filepath = config['path']['model_dir'] + \\\n",
    "    \"model-\"+name+\"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.init(config=params, project='lstm-multi-track-js-fake')\n",
    "    callbacks.append(WandbCallback(\n",
    "        log_weights=True, log_evaluation=False, validation_steps=5))\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'], verbose=1, callbacks=callbacks)\n",
    "\n",
    "if outputs['wandb']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Single Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = np.array([trainData[0, initBeatIndex:initBeatIndex+params['sequence_length']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 'model-single-track-lstm-training-2-496-1.3643.hdf5'\n",
    "\n",
    "model = makeSingleTrackModel(track, 1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = pred.numpy().squeeze()\n",
    "\n",
    "music_sequence = []\n",
    "\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    topk = tf.math.top_k(pred[-1], 3)\n",
    "    topkChoices = topk[1].numpy().squeeze()\n",
    "    topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "    # Apply random\n",
    "    next_beat = None\n",
    "    if np.random.uniform(0, 1) < .5:\n",
    "        next_beat = topkChoices[0]\n",
    "    else:\n",
    "        p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "        next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "    music_sequence.append(idx2beat[track][next_beat])\n",
    "\n",
    "    pred = model(np.array([[next_beat]]))\n",
    "    pred = tf.expand_dims(pred, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Multi Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBeatIndex = random.randint(0, len(trainData[0])-params['sequence_length'])\n",
    "initBeat = []\n",
    "for track in range(params['track_size']):\n",
    "    initBeat.append(np.array([trainData[track, initBeatIndex:initBeatIndex+params['sequence_length']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 'model-multi-track-lstm-training-4-998-1.0914.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeMultiTrackModel(1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(os.path.join(pathes['model_dir'], weight))\n",
    "model.reset_states()\n",
    "pred = model(initBeat)\n",
    "pred = [p.numpy().squeeze() for p in pred]\n",
    "\n",
    "music_sequence = []\n",
    "for track in range(params['track_size']):\n",
    "    music_sequence.append([idx2beat[track][idx] for idx in initBeat[track][0].tolist()])\n",
    "\n",
    "outputs['length'] = 100\n",
    "for i in tqdm(range(outputs['length'])):\n",
    "\n",
    "    nextBeatList = []\n",
    "    for index, p in enumerate(pred):\n",
    "        topk = tf.math.top_k(p[-1], 3)\n",
    "        topkChoices = topk[1].numpy().squeeze()\n",
    "        topkValues = topk[0].numpy().squeeze()\n",
    "\n",
    "        # Apply random\n",
    "        # next_beat = topkChoices[0]\n",
    "        next_beat = None\n",
    "        if np.random.uniform(0, 1) < .5:\n",
    "            next_beat = topkChoices[0]\n",
    "        else:\n",
    "            p_choices = tf.math.softmax(topkValues[1:]).numpy()\n",
    "            next_beat = np.random.choice(topkChoices[1:], 1, p=p_choices)[0]\n",
    "\n",
    "        music_sequence[index].append(idx2beat[index][next_beat])\n",
    "        nextBeatList.append(np.array([[next_beat]]))\n",
    "\n",
    "    pred = model.predict(nextBeatList, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi('new100-4-2'+'.mid', music_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateMidi(name+'.mid', [music_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=name+'.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('lofi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af42d6b00596c858df57cfb1e3d56019ad36764fdda4c39cb12fa72d6aaee7c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
